---
title: "5(b). Trend and Seasonal Methods"
author: "Ankit"
date: "2/4/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Holt's linear trend method :-
This method extends the simple exponential smoothing to allow the forecasting of data with a trend.

This method has 2 smoothing equations and 1 forecast equations:-

**Forecast Equation :- ** $\hat y_{t+h|t} = l_t + hb_t$.

**Level Equation :- ** $l_t = αy_t + (1-α)(l_{t-1} + b_{t-1})$.

**Trend Equation :- ** $b_t = β^* (l_t-l_{t-1}) + (1-β^*)b_{t-1}$.

$l_t$ = estimate of level at time t.
$b_t$ = estimate of trend at time t. 

α is smooting parameter for level and $β^*$ is the smoothing parameter for trend. Both takes values between 0 and 1.

As with simple exponential smoothing, the level $l_t$ is the weighted average of the observation $y_t$ and the one-step training forecast of for time t, here given by $l_{t-1} + b_{t-1}$.
The trend component is the weighted average of estimated trend at time t based on $l_t - l_{t-1}$ and previous estimate of trend $b_{t-1}$.

**Example :- Air Passanger data**
```{r}
library(fpp2)
autoplot(window(ausair, start = 1990)) +
  xlab("Year") + ylab("") 
```

The timeplot shows that there is an increasing trend in the data.
The smoothing parameters α, $β^*$, $l_o$, $b_o$ are estimated by minimising the SSE for the one-step training errors.
We are fitting a holt's method on this data.
```{r}
air = window(ausair, start = 1990)
fc = holt(air, h = 5)
fc$model
```

The value of α = 0.8302.
$β^*$ = 0.0001.
The very small value of $β^*$ means that slope hardly changes over time.

The Holt's method assumes that the trend is constantly increasing or decreasing with time. This might leads to over forecast for a longer forecast horizons.

###Damped Trend Methods :-
This method introduces a parameter(ϕ) that "dampens" the trend to a flat line sometime in the future.

**Forecast Equation :- ** $\hat y_{t+h|t} = l_t + (ϕ + ϕ^2 + ϕ^3 + ...... ϕ^h)b_t$.

**Level Equation :- ** $l_t = αy_t + (1-α)(l_{t-1} + ϕb_{t-1})$.

**Trend Equation :- ** $b_t = β^* (l_t-t_{t-1}) + (1-β^*)ϕb_{t-1}$.

If ϕ = 1, the method is equal to Holt's linear method. For values between 0 and 1, ϕ dampens the trend so that it approaches a constant some time in the future. In fact, the forecasts converge to $l_T + ϕb_T/(1-ϕ)$ as h -> ∞.for any value 0<ϕ<1.This means that short-run forecasts are trended while long-run forecasts are constant.

```{r}
fc = holt(air,h =15)
fc2 = holt(air, damped = TRUE, phi = 0.9, h = 15)
autoplot(air) +
  autolayer(fc, series = "Holt's Method", PI = FALSE) +
  autolayer(fc2, series = "Damped Holt's Method", PI = FALSE) +
  xlab("Year") + ylab("Air passengers in Australia (millions)") +
  ggtitle("Forecasts from Holt's method") +
  guides(colour = guide_legend(title = "Forecasts"))
```

The red line shows the forecast using dampning effect and blue one shows forecast with no dampning effect.

Now we will compare the forecast accuracy 3 methods, Simple Exponential Smoothing, Holt's Method and Damped Holt's method.
```{r}
autoplot(livestock) +
  xlab("year") + ggtitle("Livestock, sheep in Asia (millions)")
```

```{r}
e1 = tsCV(livestock, ses, h = 1)
e2 = tsCV(livestock, holt, h = 1)
e3 = tsCV(livestock, holt, damped = TRUE, h = 1)

print ("Compare MSE")
print(c('CV error from SES :-', mean(e1^2, na.rm = TRUE)))
print(c('CV error from Holt :-', mean(e2^2, na.rm = TRUE)))
print(c('CV error from Damped Holt :-', mean(e3^2, na.rm = TRUE)))

print ("Compare MAE")
print(c('CV error from SES :-', mean(abs(e1), na.rm = TRUE)))
print(c('CV error from Holt :-', mean(abs(e2), na.rm = TRUE)))
print(c('CV error from Damped Holt :-', mean(abs(e3), na.rm = TRUE)))

```

Damped Holt's method seems to gives best result on MSE and MAE.

```{r}
fc = holt(livestock, damped = TRUE)
fc[["model"]]
```

Slope parameter is close to zero that means slope of trend is not changing with time.
level parameter is close to one, showing that level reacts strongly to each new observations.

```{r}
autoplot(fc) +
  xlab("Year") + ggtitle("Livestock, sheep in Asia (millions)")
```

The wide prediction interval reflecting the variation in the historical data but the forecast looks reasonable.

### Holt-Winters' Seasonal method :-
This method extends Holt's method to capture seasonality. Now we have 3 smoothing equations for level, trend and seasonality. 

There are 2 variations in this method. The additive model is preferred when the seasonal variations are roughly constant through the series, while the multiplicative method is preferred when the seasonal variations are changing proportional to the level of the series. 

With the additive method, the seasonality is expressed in absolute terms in the scale of the observed time series. The seasonal component in each year will sum up to zero. 
With the multiplicative method, the seasonal component are expressed in relative terms. The seasonal component in each year will sum up to m(frequency).

##### Additive Method :-
The component form of the additive method is :-

**Forecast Equation :- ** $\hat y_{t+h|t} = l_t + hb_t + s_{t+h-m(k+1)}$.

**Level Equation :- ** $l_t = α(y_t - s_{t-m}) + (1-α)(l_{t-1} + b_{t-1})$.

**Trend Equation :- ** $b_t = β^* (l_t-t_{t-1}) + (1-β^*)b_{t-1}$.

**Seasonality Equation :- ** $s_t = γ(y_t - l_{t-1} - b_{t-1}) + (1-γ)s_{t-m}$

where k = (h-1)/m, which ensures that the estimates of the seasonal indices for forecasting come from the final year of the sample. The level shows the weighted average between the seasonal adjusted observation($y_t - s_{t-m}$) and the non-seasonal forecasts ($l_{t-1} + b_{t-1}$) for time t.  
Trend equation shows the weighted average of estimated trend at t and estimate of the prevoius trend.
Seasonality is the weighted average of current seasonal index and seasonal index of same season last year.

##### Mutiplicative Method :-
The component form of the multiplicative method is :-

**Forecast Equation :- ** $\hat y_{t+h|t} = (l_t + hb_t) * s_{t+h-m(k+1)}$.

**Level Equation :- ** $l_t = α\frac{y_t}{s_{t-m}} + (1-α)(l_{t-1} + b_{t-1})$.

**Trend Equation :- ** $b_t = β^* (l_t-t_{t-1}) + (1-β^*)b_{t-1}$.

**Seasonality Equation :- ** $s_t = γ \frac{y_t}{l_{t-1} + b_{t-1}} + (1-γ)s_{t-m}$

**Example - International tourists visitor nights in Australia **

```{r}
aust = window(austourists, start = 2005)
fit1 = hw(aust, seasonal = "additive")
fit2 = hw(aust, seasonal = "multiplicative")
autoplot(aust) +
  autolayer(fit1, series = "HW additive forecasts", PI = FALSE) +
  autolayer(fit2, series = "HW multiplicative forecasts", PI = FALSE) +
  xlab("Year") + ylab("Visitor Nights (millions)") +
  ggtitle("International visitor nights in Australia") +
  guides(colour = guide_legend(title = "Forecasts"))
```

The data shows that the seasonality is proportional to the level. A multiplicative model should work better than additive model. The forecasts also shows that the additive model is giving constant seasonality but seasonality from mutiplicative approach is increasing in size.

```{r}
fit1[["model"]]
fit2[["model"]]
```

We can see that the AIC, AICc and BIC are smaller for multiplicative model.

##### Holt-Winters' damped method :-
We can use dampning in both additive and multiplicative method, the Holt-Winters' damped method applies dampning on both trend and seasonality.

**Multiplicative Model :-**

**Forecast Equation :- ** $\hat y_{t+h|t} = [l_t + (ϕ + ϕ^2 + ϕ^3 + ...... ϕ^h)b_t] s_{t+h -m(k+1)}$

**Level Equation :- ** $l_t = α \frac{y_t}{s_{t-m}} + (1-α)(l_{t-1} + ϕb_{t-1})$.

**Trend Equation :- ** $b_t = β^* (l_t-t_{t-1}) + (1-β^*)ϕb_{t-1}$.

**Seasonality Equation :- ** $s_t = γ \frac{y_t}{l_{t-1} + ϕb_{t-1}} + (1-γ)s_{t-m}$

**Example :-**

```{r}
fc = hw(subset(hyndsight, end = length(hyndsight)-35),
        damped = TRUE, seasonal = "multiplicative", h = 35)
autoplot(hyndsight) +
  autolayer(fc, series = "HW multi damped", PI = FALSE) +
  guides(colour = guide_legend(title = "Forecasts"))
```

Clearly the model has identified the weekly seasonal pattern and the increasing trend at the end of the data, and the forecasts are a close match to the test data.

#### Excercise

**6. Holt' method on the books data**
```{r}
holtfc_pb = holt(books[,1], h = 4)
autoplot(holtfc_pb) + 
  autolayer(fitted(holtfc_pb), series = "Fitted") +
  xlab("Day") +
  ylab("No. of books")
holtfc_pb$model

print(c("RMSE",sqrt(mean((books[,1] - fitted(holtfc_pb))^2))))
```

```{r}
holtfc_hc = holt(books[,2], h = 4)
autoplot(holtfc_hc) + 
  autolayer(fitted(holtfc_hc), series = "Fitted") +
  xlab("Day") +
  ylab("No. of books")
holtfc_hc$model

print(c("RMSE",sqrt(mean((books[,2] - fitted(holtfc_hc))^2))))
```
The small values of alpha and beta shows that trend do not change much overtime. Also the RMSE has decreased from simple SES.

95% Forecast interval :-
```{r}
print(c("lower limit" , holtfc_pb$mean[1] - 1.96 * sd(residuals(holtfc_pb))))

print(c("upper limit",holtfc_pb$mean[1] + 1.96 * sd(residuals(holtfc_pb))))
```

**7. Holt' method on eggs data**
```{r}
autoplot(eggs) +
  xlab("Year") + ylab("") + ggtitle("Price of dozen eggs in US")
```

```{r}
eggs_fc = holt(eggs, h = 50)
autoplot(eggs_fc) + 
  autolayer(fitted(eggs_fc), series = "Fitted Values") +
  xlab("Year") + ylab("") +
  ggtitle("Price of dozen eggs in US")
accuracy(eggs_fc)
```

Holt's method with a dampning effect
```{r}
eggs_fc = holt(eggs, h = 10, lambda = BoxCox.lambda(eggs), damped = TRUE)
autoplot(eggs_fc) + 
  autolayer(fitted(eggs_fc), series = "Fitted Values") +
  xlab("Year") + ylab("") +
  ggtitle("Price of dozen eggs in US")

accuracy(eggs_fc)
```

**8. Retail Time Series Data **
```{r}
retaildata = readxl::read_excel("/Users/atyagi/Desktop/Time Series Forecasting/Time-Series-Forecasting/Time_series_data/retail.xlsx",skip =1)
myts = ts(retaildata[,"A3349873A"], start = c(1984,4), frequency = 12)
autoplot(myts)
```

This time has an increasing trend and seasonality present that increase in size with level of the series. We can either assume a multiplicative model or we can apply BoxCox transformation and fit an additive model.
```{r}
retail_fc = hw(myts, seasonal = "multiplicative", h = 50)
autoplot(retail_fc) +
  autolayer(fitted(retail_fc), series = "Fitted") +
  xlab("Year") + ylab("")

e = tsCV(myts, hw, h = 1, seasonal = "multiplicative")
writeLines("RMSE using Holt Winters method assuming multiplicative seasonality")
sqrt(mean(e^2, na.rm = TRUE))
```

It seems that the multiplicative model fits the data quite well. But the high prediction interval shows high uncertainity related to the forecast.

We will see if dampning the effect will give us a better result.
```{r}
retail_fc = hw(myts, seasonal = "multiplicative", h = 50, damped = TRUE)
autoplot(retail_fc) +
  autolayer(fitted(retail_fc), series = "Fitted") +
  xlab("Year") + ylab("")

e = tsCV(myts, hw, h = 1, seasonal = "multiplicative", damped = TRUE)
writeLines("RMSE using Holt Winters method assuming multiplicative seasonality")
sqrt(mean(e^2, na.rm = TRUE))
```

we will cehck wheather the residuals looks like white noise or not.
```{r}
checkresiduals(retail_fc)
```

The residuals do not looks like white noise. The ACF plot shows significant correlation between lags. LB test is also proves the same.

We will calculate test set errors.
```{r}
ts_retail_train <- window(myts,
                          end = c(2010, 12))
ts_retail_test <- window(myts,
                         start = 2011)

ts_retail_train_fc = hw(ts_retail_train, seasonal = "multiplicative", h = 50, damped = TRUE)
accuracy(ts_retail_train_fc, ts_retail_test)
```

The RMSE on the training set much higher than what we have calculated using sesonal naive method (25.09626).

